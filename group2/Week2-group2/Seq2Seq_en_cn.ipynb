{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# The Task at Hand\n",
    "\n",
    "Have you ever wondered if computers could translate languages? Did you think google translate or duolingo worked because they memorized answers? \n",
    "\n",
    "The type of problem that translation solves is sequence to sequence. For instance, we could convert an english input sequence to a german output sequence. \n",
    "\n",
    "In this activity, we will create an english -> chinese translator and apply what we've been learning about LSTMs & RNNs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preparing the data\n",
    "We need to import our packages and data to learn a little bit about the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "id": "PS0kPzE04YFO"
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from Word2Sequence import Word2Sequence\n",
    "from Dataset import Dataset\n",
    "from Seq2Seq import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# read small_en-cn.txt file\n",
    "data_path = './eng-chin.txt'\n",
    "df = pd.read_table(data_path,header=None).iloc[:,:]\n",
    "df = df.drop([2],axis=1)\n",
    "df.columns=['english','chinese']\n",
    "\n",
    "input_texts = df.english.values.tolist() #this will be all of the english sentences\n",
    "target_texts = df.chinese.values.tolist() #this will be all of the chinese sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['有没有一个国家比美国更提倡爱国主义？', '有空的时候，我总喜欢听古典音乐。', '我九岁的时候问我妈妈圣诞老人是否真的存在。', '我是外国人，我捷克语不好，请说慢一点。', '如果可能的話, 我希望你參加下一次的會議。', '如果你喜歡你做的工作，你就有比金錢更有價值的東西。', '直到我自己有了孩子我才明白了什么是母爱。', '善良是聾子能聽盲人能看的語言。', '玛丽哭着从学校跑回了家里，因为她的朋友捉弄了她。', '我爸爸对我的爱和照顾不比我妈妈少。', '现在是你决定是不是真要结婚的时候。', '人會因為體溫而在紅外線攝影機上顯現。', '警察大概从一个月前就开始找被偷物品了。', '他們告訴我吃完這個藥我就會覺得舒服一點。', '因为家里钱不够所以汤姆没能念大学。', '他的食物供给不足的的时候，他不得不去找新的地方居住。', '我昨晚在床上看书的时候点着灯就睡了。', '“你去哪儿了？”“我去了火车站送我的一个朋友。”', '对了，前些时间你说伞不见了，现在找到了吗？', '當她看到媽媽沒在生她的氣，她的雙眼因為幸福而閃爍了。', '我不用曲膝就能把我的手掌放到地上。', '我十八歲時，學了開車、考到了駕照。', '我十八歲時，學了開車、考到了駕照。', '我本来预备今天去海滩的，但接着天就开始下雨了。', '如果我们知道我们在做什么，那么这不能称之为研究，是吗？', '如果你想去，就去好了。如果你不想去，那也没什么大不了的。', '在美国，大多数人能在十八岁后投票选举。', '得不到的东西就最想得到。', '比起少抽菸，你何不直接把菸戒了？', '反社会者极少为他们的罪行显露懊悔或有罪恶的感觉。', '汤姆不能说明玛丽遇害那天自己在哪里。', '汤姆从没忘记在婚礼周年纪念日送给他妻子花。', '在巴黎，沒有人能夠理解湯姆的法文。', '我们那时在谈论事情，但我不记得是什么了。', '你不应该在社交网络上分享过多私人信息。', '湯姆失業後，為了排遣鬱悶的心情而開始了賭博。', '放學後，我到一所英語學校去練習英語會話。', '我想你要拿到驾照根本不难。', '我以为我们发现了绝妙的藏身之处，但警察找到了我们。', '我想知道最近的美國運通辦事處的電話號碼。', '她定期去看牙医，所以她很少牙痛。', '让事情更糟糕的是，他没有注意到他打扰到了邻居。', '你似乎對來自國外的想法有偏見。', '如果一個病人折一千隻紙鶴, 她的願望就會成真。', '真难相信汤姆不知道玛丽爱他。', '汤姆在夏休回乡看望父母。', '筹划旅行的时候，我们必须考虑到全家人的意愿。', '如果你不会说英语，你就很难得到一个好的职位。', '我到櫃檯拿了鑰匙，然後就乘電梯去了我房間的樓層。', '英语现已成为世界上许多国家的通用语言了。', '在校外，她见到没有家的人们住在纸板箱里。', '總理的發言估計激怒了在野黨。', '这电子辞典的好处就是便于携带。', '當這位女士得知她已經贏得了百萬美元, 她真的樂瘋了。', '我们对这次的延迟表示抱歉，并对可能造成的不便表示遗憾。', '根據報載，有一架飛機昨天晚上發生了意外。', '從他大學畢業以後, 他教了兩年的英語。', '如果一个人有11只羊，除了9只之外，其他全部死了，那么他还剩下几只羊呢？', '如果那天下雨，比赛会顺延至下一个晴天。', '给你解释这为什么行不通要花很多时间。', '该国严禁进口稀有野生动物。', '忠犬八公的雕像伫立在涩谷站前。', '每一個人對事情的看法不同是依據他們是富有還是貧窮。', '尽管政府拒绝承认，它的经济政策还是失败了。', 'Mary试图把围裙围在腰上，然后把烤鸡从炉子里拿出来。', '人們看待事情的角度不同取決於他們是富裕或貧窮。', '倫敦的人口遠遠多於其他英國城市的人口。', '他们认为，去反驳一个不认识的人有些不礼貌。', '四分之三的美国人相信存在超自然现象。', '汤姆得出无论他做什么，玛丽都不会喜欢的结论。', '全世界百分之八十電腦上的資訊都是用英語寫的。', '我以为我们发现了绝妙的藏身之处，但警察找到了我们。', '早上起来，嗓子变得很沙哑，我想是不是感冒了。', '如果看起来像个苹果而且吃起来也像苹果的话，可能就是苹果。', '世界就像是一本书，走一步等于翻了一页。', '今天，我本打算在图书馆学习但到12点左右才醒。', 'Tom写作可以写的像本国人一样，可是他的发音很烂', '汤姆尽了全力，但他还是不能获得比玛丽更高的等级。', '当列车停止时，所有的乘客都想知道发生了什么。', 'Charles Lindbergh於1927年成功完成了第一次獨自飛越大西洋。', '他的分数总比我高，尽管他学习得少一点。', '其实我工作并不多，但足以让我这周在办公室里忙着了。', '我还了从图书馆借的书，又借了些新的。', '文章的发表被预定在教授生日那天。', '她受歡迎不是因為她的美麗，而是因為她親切地對待每個人。', '电话运营商提示来电人等候接通。', '那些说钱不能买来幸福的人，只是不知道上哪里去买而已。', '當時沒有任何以英語為母語的人在公立學校任教。', '如果你远离危险区域，里约热内卢就是完全安全的。', '她被要求去说服他以让他或者他的儿子或者是别的人来粉刷屋子。', '汤姆总是说话声音太小，我几乎听不懂他在说什么。', '尽管我在学校学了6年英语，我还是说不好。', '我为自己买了副羽毛球拍，但我忘记买羽毛球了。', '我不知道这个城市，而且我一点都不懂那里的语言。', '两个孩子的年龄加起来和他们的父亲相当。', '对工具箱里只有一把榔头的人来说，所有的问题都像钉子。', '汤姆去河里游泳，但当他出来时，他的衣服被偷了。', '作為一個良好的交談者，並不只意味著作一個英語說得好的說話者。', '人孔是圓的，因為這樣人孔蓋就不會意外地掉進洞裡。']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: Try printing some english and chinese sentences from their lists input_texts and target_texts!\n",
    "'''\n",
    "print(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "id": "cPXhq9PO4dOC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['does',\n",
       "  'any',\n",
       "  'other',\n",
       "  'country',\n",
       "  'fan',\n",
       "  'the',\n",
       "  'flames',\n",
       "  'of',\n",
       "  'patriotism',\n",
       "  'as',\n",
       "  'much',\n",
       "  'as',\n",
       "  'america',\n",
       "  '?'],\n",
       " ['i',\n",
       "  'always',\n",
       "  'enjoy',\n",
       "  'listening',\n",
       "  'to',\n",
       "  'classical',\n",
       "  'music',\n",
       "  'when',\n",
       "  'i',\n",
       "  'have',\n",
       "  'some',\n",
       "  'free',\n",
       "  'time',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'was',\n",
       "  'nine',\n",
       "  'years',\n",
       "  'old',\n",
       "  'when',\n",
       "  'i',\n",
       "  'asked',\n",
       "  'my',\n",
       "  'mom',\n",
       "  'if',\n",
       "  'santa',\n",
       "  'claus',\n",
       "  'really',\n",
       "  'existed',\n",
       "  '.'],\n",
       " ['i',\n",
       "  \"'\",\n",
       "  'm',\n",
       "  'a',\n",
       "  'foreigner',\n",
       "  'and',\n",
       "  'i',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'czech',\n",
       "  'very',\n",
       "  'well',\n",
       "  '.',\n",
       "  'please',\n",
       "  ',',\n",
       "  'speak',\n",
       "  'slowly',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'at',\n",
       "  'all',\n",
       "  'possible',\n",
       "  ',',\n",
       "  'i',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'like',\n",
       "  'you',\n",
       "  'to',\n",
       "  'take',\n",
       "  'part',\n",
       "  'in',\n",
       "  'the',\n",
       "  'next',\n",
       "  'meeting',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'you',\n",
       "  'enjoy',\n",
       "  'the',\n",
       "  'work',\n",
       "  'you',\n",
       "  'do',\n",
       "  ',',\n",
       "  'you',\n",
       "  'have',\n",
       "  'something',\n",
       "  'worth',\n",
       "  'more',\n",
       "  'than',\n",
       "  'money',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'was',\n",
       "  'not',\n",
       "  'until',\n",
       "  'i',\n",
       "  'had',\n",
       "  'a',\n",
       "  'baby',\n",
       "  'myself',\n",
       "  'that',\n",
       "  'i',\n",
       "  'knew',\n",
       "  'what',\n",
       "  'mother',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'love',\n",
       "  'is',\n",
       "  '.'],\n",
       " ['kindness',\n",
       "  'is',\n",
       "  'the',\n",
       "  'language',\n",
       "  'which',\n",
       "  'the',\n",
       "  'deaf',\n",
       "  'can',\n",
       "  'hear',\n",
       "  'and',\n",
       "  'the',\n",
       "  'blind',\n",
       "  'can',\n",
       "  'see',\n",
       "  '.'],\n",
       " ['mary',\n",
       "  'came',\n",
       "  'home',\n",
       "  'from',\n",
       "  'school',\n",
       "  'in',\n",
       "  'tears',\n",
       "  'because',\n",
       "  'her',\n",
       "  'friends',\n",
       "  'had',\n",
       "  'teased',\n",
       "  'her',\n",
       "  '.'],\n",
       " ['my',\n",
       "  'father',\n",
       "  'was',\n",
       "  'no',\n",
       "  'less',\n",
       "  'affectionate',\n",
       "  'and',\n",
       "  'tender',\n",
       "  'to',\n",
       "  'me',\n",
       "  'than',\n",
       "  'my',\n",
       "  'mother',\n",
       "  'was',\n",
       "  '.'],\n",
       " ['now',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'the',\n",
       "  'time',\n",
       "  'to',\n",
       "  'decide',\n",
       "  'whether',\n",
       "  'you',\n",
       "  'really',\n",
       "  'want',\n",
       "  'to',\n",
       "  'get',\n",
       "  'married',\n",
       "  'or',\n",
       "  'not',\n",
       "  '.'],\n",
       " ['people',\n",
       "  'show',\n",
       "  'up',\n",
       "  'bright',\n",
       "  'on',\n",
       "  'an',\n",
       "  'infrared',\n",
       "  'camera',\n",
       "  'because',\n",
       "  'of',\n",
       "  'their',\n",
       "  'body',\n",
       "  'heat',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'police',\n",
       "  'have',\n",
       "  'been',\n",
       "  'searching',\n",
       "  'for',\n",
       "  'the',\n",
       "  'stolen',\n",
       "  'goods',\n",
       "  'for',\n",
       "  'almost',\n",
       "  'a',\n",
       "  'month',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'told',\n",
       "  'me',\n",
       "  'that',\n",
       "  'i',\n",
       "  'would',\n",
       "  'feel',\n",
       "  'a',\n",
       "  'little',\n",
       "  'better',\n",
       "  'if',\n",
       "  'i',\n",
       "  'took',\n",
       "  'this',\n",
       "  'medicine',\n",
       "  '.'],\n",
       " ['tom',\n",
       "  'couldn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'go',\n",
       "  'to',\n",
       "  'college',\n",
       "  'because',\n",
       "  'his',\n",
       "  'family',\n",
       "  'didn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'have',\n",
       "  'enough',\n",
       "  'money',\n",
       "  '.'],\n",
       " ['when',\n",
       "  'his',\n",
       "  'food',\n",
       "  'supply',\n",
       "  'ran',\n",
       "  'short',\n",
       "  ',',\n",
       "  'he',\n",
       "  'had',\n",
       "  'to',\n",
       "  'look',\n",
       "  'for',\n",
       "  'a',\n",
       "  'new',\n",
       "  'place',\n",
       "  'to',\n",
       "  'live',\n",
       "  '.'],\n",
       " ['while',\n",
       "  'i',\n",
       "  'was',\n",
       "  'reading',\n",
       "  'in',\n",
       "  'bed',\n",
       "  'last',\n",
       "  'night',\n",
       "  ',',\n",
       "  'i',\n",
       "  'fell',\n",
       "  'asleep',\n",
       "  'with',\n",
       "  'the',\n",
       "  'light',\n",
       "  'on',\n",
       "  '.'],\n",
       " ['where',\n",
       "  'have',\n",
       "  'you',\n",
       "  'been',\n",
       "  '?',\n",
       "  '\"',\n",
       "  'i',\n",
       "  'have',\n",
       "  'been',\n",
       "  'to',\n",
       "  'the',\n",
       "  'station',\n",
       "  'to',\n",
       "  'see',\n",
       "  'a',\n",
       "  'friend',\n",
       "  'off',\n",
       "  '.\"'],\n",
       " ['by',\n",
       "  'the',\n",
       "  'way',\n",
       "  ',',\n",
       "  'did',\n",
       "  'you',\n",
       "  'find',\n",
       "  'the',\n",
       "  'umbrella',\n",
       "  'you',\n",
       "  'said',\n",
       "  'you',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'lost',\n",
       "  'the',\n",
       "  'other',\n",
       "  'day',\n",
       "  '?'],\n",
       " ['her',\n",
       "  'eyes',\n",
       "  'shone',\n",
       "  'with',\n",
       "  'joy',\n",
       "  'when',\n",
       "  'she',\n",
       "  'saw',\n",
       "  'that',\n",
       "  'her',\n",
       "  'mother',\n",
       "  'was',\n",
       "  'not',\n",
       "  'mad',\n",
       "  'at',\n",
       "  'her',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'can',\n",
       "  'place',\n",
       "  'the',\n",
       "  'palms',\n",
       "  'of',\n",
       "  'my',\n",
       "  'hands',\n",
       "  'on',\n",
       "  'the',\n",
       "  'floor',\n",
       "  'without',\n",
       "  'bending',\n",
       "  'my',\n",
       "  'knees',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'learned',\n",
       "  'to',\n",
       "  'drive',\n",
       "  'a',\n",
       "  'car',\n",
       "  'and',\n",
       "  'got',\n",
       "  'a',\n",
       "  'driver',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'license',\n",
       "  'when',\n",
       "  'i',\n",
       "  'was',\n",
       "  'eighteen',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'learned',\n",
       "  'to',\n",
       "  'drive',\n",
       "  'a',\n",
       "  'car',\n",
       "  'when',\n",
       "  'i',\n",
       "  'was',\n",
       "  'eighteen',\n",
       "  'and',\n",
       "  'got',\n",
       "  'a',\n",
       "  'driver',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'license',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'was',\n",
       "  'planning',\n",
       "  'on',\n",
       "  'going',\n",
       "  'to',\n",
       "  'the',\n",
       "  'beach',\n",
       "  'today',\n",
       "  ',',\n",
       "  'but',\n",
       "  'then',\n",
       "  'it',\n",
       "  'started',\n",
       "  'to',\n",
       "  'rain',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'we',\n",
       "  'knew',\n",
       "  'what',\n",
       "  'we',\n",
       "  'were',\n",
       "  'doing',\n",
       "  ',',\n",
       "  'it',\n",
       "  'wouldn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'be',\n",
       "  'called',\n",
       "  'research',\n",
       "  ',',\n",
       "  'would',\n",
       "  'it',\n",
       "  '?'],\n",
       " ['if',\n",
       "  'you',\n",
       "  'want',\n",
       "  'to',\n",
       "  'go',\n",
       "  ',',\n",
       "  'then',\n",
       "  'go',\n",
       "  '.',\n",
       "  'if',\n",
       "  'you',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'want',\n",
       "  'to',\n",
       "  ',',\n",
       "  'then',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'no',\n",
       "  'big',\n",
       "  'deal',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'the',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.,',\n",
       "  'most',\n",
       "  'people',\n",
       "  'can',\n",
       "  'vote',\n",
       "  'when',\n",
       "  'they',\n",
       "  'reach',\n",
       "  'eighteen',\n",
       "  'years',\n",
       "  'of',\n",
       "  'age',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'the',\n",
       "  'things',\n",
       "  'that',\n",
       "  'we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'possess',\n",
       "  'which',\n",
       "  'seem',\n",
       "  'to',\n",
       "  'us',\n",
       "  'most',\n",
       "  'desirable',\n",
       "  '.'],\n",
       " ['rather',\n",
       "  'than',\n",
       "  'cutting',\n",
       "  'down',\n",
       "  'on',\n",
       "  'cigarettes',\n",
       "  ',',\n",
       "  'why',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'you',\n",
       "  'just',\n",
       "  'give',\n",
       "  'them',\n",
       "  'up',\n",
       "  '?'],\n",
       " ['sociopaths',\n",
       "  'rarely',\n",
       "  'display',\n",
       "  'remorse',\n",
       "  'or',\n",
       "  'feelings',\n",
       "  'of',\n",
       "  'guilt',\n",
       "  'for',\n",
       "  'their',\n",
       "  'crimes',\n",
       "  '.'],\n",
       " ['tom',\n",
       "  'can',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'account',\n",
       "  'for',\n",
       "  'his',\n",
       "  'whereabouts',\n",
       "  'on',\n",
       "  'the',\n",
       "  'day',\n",
       "  'that',\n",
       "  'mary',\n",
       "  'was',\n",
       "  'murdered',\n",
       "  '.'],\n",
       " ['tom',\n",
       "  'never',\n",
       "  'forgets',\n",
       "  'to',\n",
       "  'give',\n",
       "  'his',\n",
       "  'wife',\n",
       "  'flowers',\n",
       "  'on',\n",
       "  'their',\n",
       "  'wedding',\n",
       "  'anniversary',\n",
       "  '.'],\n",
       " ['tom',\n",
       "  'was',\n",
       "  'able',\n",
       "  'to',\n",
       "  'make',\n",
       "  'himself',\n",
       "  'understood',\n",
       "  'in',\n",
       "  'french',\n",
       "  'when',\n",
       "  'he',\n",
       "  'visited',\n",
       "  'paris',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'were',\n",
       "  'talking',\n",
       "  'about',\n",
       "  'something',\n",
       "  'at',\n",
       "  'that',\n",
       "  'time',\n",
       "  ',',\n",
       "  'but',\n",
       "  'i',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'remember',\n",
       "  'what',\n",
       "  '.'],\n",
       " ['you',\n",
       "  'shouldn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'share',\n",
       "  'too',\n",
       "  'much',\n",
       "  'private',\n",
       "  'information',\n",
       "  'on',\n",
       "  'the',\n",
       "  'social',\n",
       "  'networks',\n",
       "  '.'],\n",
       " ['after',\n",
       "  'tom',\n",
       "  'lost',\n",
       "  'his',\n",
       "  'job',\n",
       "  ',',\n",
       "  'he',\n",
       "  'started',\n",
       "  'to',\n",
       "  'gamble',\n",
       "  'to',\n",
       "  'cope',\n",
       "  'with',\n",
       "  'his',\n",
       "  'depression',\n",
       "  '.'],\n",
       " ['after',\n",
       "  'school',\n",
       "  ',',\n",
       "  'i',\n",
       "  'go',\n",
       "  'to',\n",
       "  'an',\n",
       "  'english',\n",
       "  'school',\n",
       "  'to',\n",
       "  'practice',\n",
       "  'english',\n",
       "  'conversation',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'think',\n",
       "  'you',\n",
       "  \"'\",\n",
       "  'll',\n",
       "  'have',\n",
       "  'very',\n",
       "  'little',\n",
       "  'difficulty',\n",
       "  'in',\n",
       "  'getting',\n",
       "  'a',\n",
       "  'driver',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'license',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'thought',\n",
       "  'we',\n",
       "  'had',\n",
       "  'found',\n",
       "  'the',\n",
       "  'perfect',\n",
       "  'hiding',\n",
       "  'place',\n",
       "  ',',\n",
       "  'but',\n",
       "  'the',\n",
       "  'police',\n",
       "  'found',\n",
       "  'us',\n",
       "  '.'],\n",
       " ['i',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'like',\n",
       "  'to',\n",
       "  'know',\n",
       "  'the',\n",
       "  'phone',\n",
       "  'number',\n",
       "  'of',\n",
       "  'the',\n",
       "  'nearest',\n",
       "  'american',\n",
       "  'express',\n",
       "  'office',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'visits',\n",
       "  'the',\n",
       "  'dentist',\n",
       "  'on',\n",
       "  'a',\n",
       "  'regular',\n",
       "  'basis',\n",
       "  ',',\n",
       "  'so',\n",
       "  'she',\n",
       "  'seldom',\n",
       "  'gets',\n",
       "  'toothaches',\n",
       "  '.'],\n",
       " ['to',\n",
       "  'make',\n",
       "  'matters',\n",
       "  'worse',\n",
       "  ',',\n",
       "  'he',\n",
       "  'isn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'even',\n",
       "  'conscious',\n",
       "  'of',\n",
       "  'annoying',\n",
       "  'his',\n",
       "  'neighbors',\n",
       "  '.'],\n",
       " ['you',\n",
       "  'seem',\n",
       "  'to',\n",
       "  'be',\n",
       "  'prejudiced',\n",
       "  'against',\n",
       "  'ideas',\n",
       "  'that',\n",
       "  'come',\n",
       "  'from',\n",
       "  'foreign',\n",
       "  'countries',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'a',\n",
       "  'sick',\n",
       "  'person',\n",
       "  'folds',\n",
       "  'one',\n",
       "  'thousand',\n",
       "  'paper',\n",
       "  'cranes',\n",
       "  ',',\n",
       "  'her',\n",
       "  'wish',\n",
       "  'will',\n",
       "  'come',\n",
       "  'true',\n",
       "  '.'],\n",
       " ['it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'tom',\n",
       "  'wasn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'aware',\n",
       "  'that',\n",
       "  'mary',\n",
       "  'was',\n",
       "  'in',\n",
       "  'love',\n",
       "  'with',\n",
       "  'him',\n",
       "  '.'],\n",
       " ['tom',\n",
       "  'returned',\n",
       "  'to',\n",
       "  'his',\n",
       "  'hometown',\n",
       "  'to',\n",
       "  'visit',\n",
       "  'his',\n",
       "  'parents',\n",
       "  'during',\n",
       "  'the',\n",
       "  'summer',\n",
       "  'break',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'must',\n",
       "  'take',\n",
       "  'into',\n",
       "  'account',\n",
       "  'the',\n",
       "  'wishes',\n",
       "  'of',\n",
       "  'all',\n",
       "  'the',\n",
       "  'family',\n",
       "  'in',\n",
       "  'planning',\n",
       "  'a',\n",
       "  'trip',\n",
       "  '.'],\n",
       " ['you',\n",
       "  \"'\",\n",
       "  're',\n",
       "  'much',\n",
       "  'less',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'get',\n",
       "  'a',\n",
       "  'good',\n",
       "  'position',\n",
       "  'if',\n",
       "  'you',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'speak',\n",
       "  'english',\n",
       "  '.'],\n",
       " ['after',\n",
       "  'asking',\n",
       "  'for',\n",
       "  'my',\n",
       "  'key',\n",
       "  'at',\n",
       "  'the',\n",
       "  'front',\n",
       "  'desk',\n",
       "  ',',\n",
       "  'i',\n",
       "  'took',\n",
       "  'the',\n",
       "  'elevator',\n",
       "  'to',\n",
       "  'my',\n",
       "  'floor',\n",
       "  '.'],\n",
       " ['english',\n",
       "  'has',\n",
       "  'now',\n",
       "  'become',\n",
       "  'the',\n",
       "  'common',\n",
       "  'language',\n",
       "  'of',\n",
       "  'several',\n",
       "  'nations',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  '.'],\n",
       " ['outside',\n",
       "  'the',\n",
       "  'school',\n",
       "  ',',\n",
       "  'she',\n",
       "  'saw',\n",
       "  'people',\n",
       "  'with',\n",
       "  'no',\n",
       "  'homes',\n",
       "  'living',\n",
       "  'in',\n",
       "  'cardboard',\n",
       "  'boxes',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'prime',\n",
       "  'minister',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'speech',\n",
       "  'was',\n",
       "  'calculated',\n",
       "  'to',\n",
       "  'anger',\n",
       "  'the',\n",
       "  'opposition',\n",
       "  'parties',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'good',\n",
       "  'thing',\n",
       "  'about',\n",
       "  'this',\n",
       "  'electronic',\n",
       "  'dictionary',\n",
       "  'is',\n",
       "  'that',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'easy',\n",
       "  'to',\n",
       "  'carry',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'lady',\n",
       "  'really',\n",
       "  'flipped',\n",
       "  'out',\n",
       "  'when',\n",
       "  'she',\n",
       "  'learned',\n",
       "  'she',\n",
       "  'had',\n",
       "  'won',\n",
       "  'a',\n",
       "  'million',\n",
       "  'dollars',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'apologize',\n",
       "  'for',\n",
       "  'the',\n",
       "  'delay',\n",
       "  'and',\n",
       "  'regret',\n",
       "  'any',\n",
       "  'inconvenience',\n",
       "  'it',\n",
       "  'may',\n",
       "  'have',\n",
       "  'caused',\n",
       "  '.'],\n",
       " ['according',\n",
       "  'to',\n",
       "  'newspaper',\n",
       "  'reports',\n",
       "  ',',\n",
       "  'there',\n",
       "  'was',\n",
       "  'an',\n",
       "  'airplane',\n",
       "  'accident',\n",
       "  'last',\n",
       "  'evening',\n",
       "  '.'],\n",
       " ['after',\n",
       "  'he',\n",
       "  'had',\n",
       "  'graduated',\n",
       "  'from',\n",
       "  'the',\n",
       "  'university',\n",
       "  ',',\n",
       "  'he',\n",
       "  'taught',\n",
       "  'english',\n",
       "  'for',\n",
       "  'two',\n",
       "  'years',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'a',\n",
       "  'man',\n",
       "  'had',\n",
       "  '11',\n",
       "  'sheep',\n",
       "  'and',\n",
       "  'all',\n",
       "  'but',\n",
       "  '9',\n",
       "  'died',\n",
       "  ',',\n",
       "  'how',\n",
       "  'many',\n",
       "  'sheep',\n",
       "  'would',\n",
       "  'he',\n",
       "  'have',\n",
       "  'left',\n",
       "  '?'],\n",
       " ['if',\n",
       "  'it',\n",
       "  'rains',\n",
       "  'on',\n",
       "  'that',\n",
       "  'day',\n",
       "  ',',\n",
       "  'the',\n",
       "  'game',\n",
       "  'will',\n",
       "  'be',\n",
       "  'postponed',\n",
       "  'until',\n",
       "  'the',\n",
       "  'next',\n",
       "  'fine',\n",
       "  'day',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'would',\n",
       "  'take',\n",
       "  'me',\n",
       "  'too',\n",
       "  'much',\n",
       "  'time',\n",
       "  'to',\n",
       "  'explain',\n",
       "  'to',\n",
       "  'you',\n",
       "  'why',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'not',\n",
       "  'going',\n",
       "  'to',\n",
       "  'work',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'importation',\n",
       "  'of',\n",
       "  'rare',\n",
       "  'wild',\n",
       "  'animals',\n",
       "  'to',\n",
       "  'this',\n",
       "  'country',\n",
       "  'is',\n",
       "  'strictly',\n",
       "  'prohibited',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'statue',\n",
       "  'of',\n",
       "  'hachiko',\n",
       "  ',',\n",
       "  'the',\n",
       "  'faithful',\n",
       "  'dog',\n",
       "  ',',\n",
       "  'stands',\n",
       "  'in',\n",
       "  'front',\n",
       "  'of',\n",
       "  'shibuya',\n",
       "  'station',\n",
       "  '.'],\n",
       " ['a',\n",
       "  'person',\n",
       "  'views',\n",
       "  'things',\n",
       "  'differently',\n",
       "  'according',\n",
       "  'to',\n",
       "  'whether',\n",
       "  'they',\n",
       "  'are',\n",
       "  'rich',\n",
       "  'or',\n",
       "  'poor',\n",
       "  '.'],\n",
       " ['although',\n",
       "  'the',\n",
       "  'government',\n",
       "  'refuses',\n",
       "  'to',\n",
       "  'admit',\n",
       "  'it',\n",
       "  ',',\n",
       "  'its',\n",
       "  'economic',\n",
       "  'policy',\n",
       "  'is',\n",
       "  'in',\n",
       "  'ruins',\n",
       "  '.'],\n",
       " ['mary',\n",
       "  'tied',\n",
       "  'an',\n",
       "  'apron',\n",
       "  'around',\n",
       "  'her',\n",
       "  'waist',\n",
       "  'and',\n",
       "  'then',\n",
       "  'took',\n",
       "  'the',\n",
       "  'turkey',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'oven',\n",
       "  '.'],\n",
       " ['people',\n",
       "  'look',\n",
       "  'at',\n",
       "  'things',\n",
       "  'differently',\n",
       "  'depending',\n",
       "  'on',\n",
       "  'whether',\n",
       "  'they',\n",
       "  'are',\n",
       "  'rich',\n",
       "  'or',\n",
       "  'poor',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'population',\n",
       "  'of',\n",
       "  'london',\n",
       "  'is',\n",
       "  'much',\n",
       "  'greater',\n",
       "  'than',\n",
       "  'that',\n",
       "  'of',\n",
       "  'any',\n",
       "  'other',\n",
       "  'british',\n",
       "  'city',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'consider',\n",
       "  'it',\n",
       "  'impolite',\n",
       "  'to',\n",
       "  'disagree',\n",
       "  'with',\n",
       "  'someone',\n",
       "  'they',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'very',\n",
       "  'well',\n",
       "  '.'],\n",
       " ['three',\n",
       "  'out',\n",
       "  'of',\n",
       "  'four',\n",
       "  'americans',\n",
       "  'believe',\n",
       "  'in',\n",
       "  'the',\n",
       "  'existence',\n",
       "  'of',\n",
       "  'paranormal',\n",
       "  'phenomena',\n",
       "  '.'],\n",
       " ['tom',\n",
       "  'came',\n",
       "  'to',\n",
       "  'the',\n",
       "  'conclusion',\n",
       "  'that',\n",
       "  'no',\n",
       "  'matter',\n",
       "  'what',\n",
       "  'he',\n",
       "  'did',\n",
       "  ',',\n",
       "  'mary',\n",
       "  'wouldn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'like',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['eighty',\n",
       "  'percent',\n",
       "  'of',\n",
       "  'all',\n",
       "  'information',\n",
       "  'on',\n",
       "  'computers',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  'is',\n",
       "  'in',\n",
       "  'english',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'thought',\n",
       "  'that',\n",
       "  'we',\n",
       "  'had',\n",
       "  'found',\n",
       "  'the',\n",
       "  'perfect',\n",
       "  'hiding',\n",
       "  'place',\n",
       "  ',',\n",
       "  'but',\n",
       "  'the',\n",
       "  'police',\n",
       "  'found',\n",
       "  'us',\n",
       "  '.'],\n",
       " ['i',\n",
       "  \"'\",\n",
       "  've',\n",
       "  'had',\n",
       "  'a',\n",
       "  'scratchy',\n",
       "  'throat',\n",
       "  'since',\n",
       "  'this',\n",
       "  'morning',\n",
       "  '.',\n",
       "  'i',\n",
       "  'wonder',\n",
       "  'if',\n",
       "  'i',\n",
       "  \"'\",\n",
       "  've',\n",
       "  'caught',\n",
       "  'a',\n",
       "  'cold',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'it',\n",
       "  'looks',\n",
       "  'like',\n",
       "  'an',\n",
       "  'apple',\n",
       "  'and',\n",
       "  'it',\n",
       "  'tastes',\n",
       "  'like',\n",
       "  'an',\n",
       "  'apple',\n",
       "  ',',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'probably',\n",
       "  'an',\n",
       "  'apple',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'world',\n",
       "  'is',\n",
       "  'just',\n",
       "  'like',\n",
       "  'a',\n",
       "  'book',\n",
       "  ',',\n",
       "  'and',\n",
       "  'every',\n",
       "  'step',\n",
       "  'you',\n",
       "  'take',\n",
       "  'is',\n",
       "  'like',\n",
       "  'turning',\n",
       "  'a',\n",
       "  'page',\n",
       "  '.'],\n",
       " ['today',\n",
       "  ',',\n",
       "  'i',\n",
       "  'was',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'study',\n",
       "  'at',\n",
       "  'the',\n",
       "  'library',\n",
       "  'but',\n",
       "  'i',\n",
       "  'woke',\n",
       "  'up',\n",
       "  'around',\n",
       "  '12',\n",
       "  'o',\n",
       "  \"'\",\n",
       "  'clock',\n",
       "  '.'],\n",
       " ['tom',\n",
       "  'can',\n",
       "  'write',\n",
       "  'almost',\n",
       "  'like',\n",
       "  'a',\n",
       "  'native',\n",
       "  'speaker',\n",
       "  ',',\n",
       "  'but',\n",
       "  'his',\n",
       "  'pronunciation',\n",
       "  'is',\n",
       "  'terrible',\n",
       "  '.'],\n",
       " ['tom',\n",
       "  'did',\n",
       "  'the',\n",
       "  'best',\n",
       "  'he',\n",
       "  'could',\n",
       "  ',',\n",
       "  'but',\n",
       "  'he',\n",
       "  'wasn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'able',\n",
       "  'to',\n",
       "  'get',\n",
       "  'a',\n",
       "  'higher',\n",
       "  'grade',\n",
       "  'than',\n",
       "  'mary',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'the',\n",
       "  'train',\n",
       "  'came',\n",
       "  'to',\n",
       "  'a',\n",
       "  'halt',\n",
       "  ',',\n",
       "  'all',\n",
       "  'of',\n",
       "  'the',\n",
       "  'passengers',\n",
       "  'wondered',\n",
       "  'what',\n",
       "  'was',\n",
       "  'happening',\n",
       "  '.'],\n",
       " ['charles',\n",
       "  'lindbergh',\n",
       "  'made',\n",
       "  'the',\n",
       "  'first',\n",
       "  'solo',\n",
       "  'flight',\n",
       "  'across',\n",
       "  'the',\n",
       "  'atlantic',\n",
       "  'ocean',\n",
       "  'in',\n",
       "  '1927',\n",
       "  '.'],\n",
       " ['his',\n",
       "  'scores',\n",
       "  'are',\n",
       "  'always',\n",
       "  'better',\n",
       "  'than',\n",
       "  'mine',\n",
       "  ',',\n",
       "  'even',\n",
       "  'though',\n",
       "  'he',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'study',\n",
       "  'very',\n",
       "  'much',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'have',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'work',\n",
       "  ',',\n",
       "  'but',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'me',\n",
       "  'in',\n",
       "  'the',\n",
       "  'office',\n",
       "  'this',\n",
       "  'week',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'returned',\n",
       "  'the',\n",
       "  'books',\n",
       "  'i',\n",
       "  'borrowed',\n",
       "  'from',\n",
       "  'the',\n",
       "  'library',\n",
       "  ',',\n",
       "  'and',\n",
       "  'i',\n",
       "  'borrowed',\n",
       "  'some',\n",
       "  'new',\n",
       "  'ones',\n",
       "  '.'],\n",
       " ['publication',\n",
       "  'of',\n",
       "  'the',\n",
       "  'article',\n",
       "  'was',\n",
       "  'timed',\n",
       "  'to',\n",
       "  'coincide',\n",
       "  'with',\n",
       "  'the',\n",
       "  'professor',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'birthday',\n",
       "  '.'],\n",
       " ['she',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'popular',\n",
       "  ',',\n",
       "  'not',\n",
       "  'because',\n",
       "  'she',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'beautiful',\n",
       "  ',',\n",
       "  'but',\n",
       "  'because',\n",
       "  'she',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'kind',\n",
       "  'to',\n",
       "  'everyone',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'telephone',\n",
       "  'operator',\n",
       "  'asked',\n",
       "  'the',\n",
       "  'caller',\n",
       "  'to',\n",
       "  'hold',\n",
       "  'on',\n",
       "  'until',\n",
       "  'a',\n",
       "  'connection',\n",
       "  'was',\n",
       "  'made',\n",
       "  '.'],\n",
       " ['whoever',\n",
       "  'said',\n",
       "  'money',\n",
       "  'can',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'buy',\n",
       "  'happiness',\n",
       "  'simply',\n",
       "  'didn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'where',\n",
       "  'to',\n",
       "  'go',\n",
       "  'shopping',\n",
       "  '.'],\n",
       " ['at',\n",
       "  'the',\n",
       "  'time',\n",
       "  'there',\n",
       "  'were',\n",
       "  'no',\n",
       "  'native',\n",
       "  'english',\n",
       "  'speakers',\n",
       "  'teaching',\n",
       "  'in',\n",
       "  'any',\n",
       "  'public',\n",
       "  'school',\n",
       "  '.'],\n",
       " ['rio',\n",
       "  'de',\n",
       "  'janeiro',\n",
       "  'is',\n",
       "  'perfectly',\n",
       "  'safe',\n",
       "  'as',\n",
       "  'long',\n",
       "  'as',\n",
       "  'you',\n",
       "  'stay',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dangerous',\n",
       "  'areas',\n",
       "  '.'],\n",
       " ['she',\n",
       "  'was',\n",
       "  'asked',\n",
       "  'to',\n",
       "  'convince',\n",
       "  'him',\n",
       "  'to',\n",
       "  'get',\n",
       "  'his',\n",
       "  'son',\n",
       "  'or',\n",
       "  'someone',\n",
       "  'else',\n",
       "  'to',\n",
       "  'paint',\n",
       "  'the',\n",
       "  'house',\n",
       "  '.'],\n",
       " ['tom',\n",
       "  'always',\n",
       "  'speaks',\n",
       "  'in',\n",
       "  'such',\n",
       "  'a',\n",
       "  'low',\n",
       "  'voice',\n",
       "  'that',\n",
       "  'i',\n",
       "  'can',\n",
       "  'barely',\n",
       "  'understand',\n",
       "  'what',\n",
       "  'he',\n",
       "  'says',\n",
       "  '.'],\n",
       " ['even',\n",
       "  'though',\n",
       "  'i',\n",
       "  'studied',\n",
       "  'english',\n",
       "  'for',\n",
       "  '6',\n",
       "  'years',\n",
       "  'in',\n",
       "  'school',\n",
       "  ',',\n",
       "  'i',\n",
       "  \"'\",\n",
       "  'm',\n",
       "  'not',\n",
       "  'good',\n",
       "  'at',\n",
       "  'speaking',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'bought',\n",
       "  'a',\n",
       "  'second',\n",
       "  'badminton',\n",
       "  'racket',\n",
       "  'for',\n",
       "  'myself',\n",
       "  ',',\n",
       "  'but',\n",
       "  'i',\n",
       "  'forgot',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'a',\n",
       "  'shuttlecock',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'didn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'the',\n",
       "  'city',\n",
       "  ',',\n",
       "  'and',\n",
       "  'what',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'more',\n",
       "  ',',\n",
       "  'i',\n",
       "  'couldn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'speak',\n",
       "  'a',\n",
       "  'word',\n",
       "  'of',\n",
       "  'the',\n",
       "  'language',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'ages',\n",
       "  'of',\n",
       "  'the',\n",
       "  'two',\n",
       "  'children',\n",
       "  'put',\n",
       "  'together',\n",
       "  'was',\n",
       "  'equivalent',\n",
       "  'to',\n",
       "  'that',\n",
       "  'of',\n",
       "  'their',\n",
       "  'father',\n",
       "  '.'],\n",
       " ['to',\n",
       "  'the',\n",
       "  'man',\n",
       "  'who',\n",
       "  'only',\n",
       "  'has',\n",
       "  'a',\n",
       "  'hammer',\n",
       "  'in',\n",
       "  'the',\n",
       "  'toolkit',\n",
       "  ',',\n",
       "  'every',\n",
       "  'problem',\n",
       "  'looks',\n",
       "  'like',\n",
       "  'a',\n",
       "  'nail',\n",
       "  '.'],\n",
       " ['tom',\n",
       "  'went',\n",
       "  'swimming',\n",
       "  'in',\n",
       "  'the',\n",
       "  'river',\n",
       "  ',',\n",
       "  'but',\n",
       "  'when',\n",
       "  'he',\n",
       "  'got',\n",
       "  'out',\n",
       "  ',',\n",
       "  'his',\n",
       "  'clothes',\n",
       "  'had',\n",
       "  'been',\n",
       "  'stolen',\n",
       "  '.'],\n",
       " ['being',\n",
       "  'a',\n",
       "  'good',\n",
       "  'conversationalist',\n",
       "  'does',\n",
       "  'not',\n",
       "  'just',\n",
       "  'mean',\n",
       "  'being',\n",
       "  'a',\n",
       "  'good',\n",
       "  'speaker',\n",
       "  'of',\n",
       "  'english',\n",
       "  '.'],\n",
       " ['manholes',\n",
       "  'are',\n",
       "  'round',\n",
       "  'because',\n",
       "  'that',\n",
       "  'way',\n",
       "  'they',\n",
       "  'won',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'accidentally',\n",
       "  'fall',\n",
       "  'through',\n",
       "  'the',\n",
       "  'hole',\n",
       "  '.']]"
      ]
     },
     "execution_count": 4,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in our model object. Tokenize our data\n",
    "tk = WordPunctTokenizer()\n",
    "english = [tk.tokenize(sentence.lower()) for sentence in input_texts]\n",
    "chinese = [[x for x in sentence] for sentence in target_texts]\n",
    "english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: Explore this data. Can you calculate the maximum length of a sequence in each dataset english and chinese?\n",
    "'''\n",
    "# calculate max_len of any sequence in 'english' list and save it to a variable called max_english_length\n",
    "max_english_length = max([len(seq) for seq in english])\n",
    "print(max_english_length)\n",
    "# calculate max_len of any sequence in 'chinese' list and save it to a variable called max_chinese_length\n",
    "max_chinese_length = max([len(seq) for seq in chinese])\n",
    "print(max_chinese_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "ZzoUqCrq4fWj",
    "outputId": "4290ee15-457e-44d7-f083-f12a2e5d78a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "317\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Word2Sequence()\n",
    "for words in english:\n",
    "    input_tokenizer.fit(words)\n",
    "input_tokenizer.build_vocab(min=1, max_features=None) #inpu\n",
    "\n",
    "output_tokenizer = Word2Sequence()\n",
    "for words in chinese:\n",
    "    output_tokenizer.fit(words)\n",
    "output_tokenizer.build_vocab(min=1, max_features=None)\n",
    "\n",
    "'''\n",
    "Your code here: print the total english words in your input tokenizer and total chinese words in your output tokenizer below!\n",
    "'''\n",
    "total_english_words = len(input_tokenizer)\n",
    "print(total_english_words)\n",
    "\n",
    "total_chinese_words = len(output_tokenizer)\n",
    "print(total_chinese_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Creating the model</h1>\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "NOTE: For Structure of Encoder Inputs, they can all be either (assume all have same maxlen): \n",
    "1. \\<SOS>, word1, word2, word3, ..., \\<EOS>\n",
    "2. word1, word2, word3, ..., \\<EOS> \n",
    "3. word1, word2, word3, ...\n",
    "\n",
    "NOTE: But Decoder In and Out structures should always look like this (assume all have same maxlen):\n",
    "- Decoder Input: \\<SOS>, word1, word2, word3, ...\n",
    "- Decoder Output: word1, word2, word3, ..., \\<EOS>  \n",
    "\n",
    "This means that our input and ouput max length should be one more than the sequence's max length.\n",
    "\n",
    "WHY? Data Structure:\n",
    "- 1. Encoder Input: [word1, word2, ... + <EOS>]\n",
    "- 2. Decoder Input: [<SOS> + word1, word2, ...]\n",
    "- 3. Decoder Output:[word1, word2, ... + <EOS>]\n",
    "    \n",
    "nn docs - https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "id": "qm_Qhnlk49Rn"
   },
   "outputs": [
   ],
   "source": [
    "# Seq2Seq Parameters\n",
    "in_maxlen = 25 + 1 # 25 + 1(<EOS> token)\n",
    "out_maxlen = 39 + 1 # 39 + 1(<EOS> token or <SOS> token)\n",
    "n_hidden = 32 # number of \"neurons\" per layer\n",
    "d_model = 64 # number of embedding dimensions to represent each word\n",
    "enc_n_class = len(input_tokenizer.dict) # OR... vocab size of englisth -> 199\n",
    "dec_n_class = len(output_tokenizer.dict) # OR... vocab size of chinese -> 317\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# max_english_length, max_chinese_length = 25, 39\n",
    "eng_maxlen = max_english_length + 1 # 25 + 1(<EOS> token)\n",
    "chin_maxlen = max_chinese_length + 1  # 39 + 1(<EOS> token or <SOS> token)\n",
    "batch_size = 1\n",
    "\n",
    "# Setup the Dataset.\n",
    "dataset = Dataset(\n",
    "    X = english,\n",
    "    Y = chinese,\n",
    "    in_tknz = input_tokenizer, out_tknz = output_tokenizer,\n",
    "    in_maxlen = eng_maxlen, out_maxlen = chin_maxlen\n",
    ")\n",
    "\n",
    "'''\n",
    "The following are helper functions to help pytorch. You won't need to know this much.\n",
    "'''\n",
    "# NOTE: collate_fn preprocesses your input from PyTorch Dataset above during PyTorch DataLoader\n",
    "def collate_fn(batch):\n",
    "    '''\n",
    "    param batch: ([enc_in, dec_in, dec_out]， [enc_in, dec_in, dec_out], output of getitem...)\n",
    "    '''\n",
    "    # unpack values\n",
    "    enc_in, dec_in, dec_out = list(zip(*batch))\n",
    "    # Return tensor type\n",
    "    return torch.LongTensor(enc_in), torch.LongTensor(dec_in), torch.LongTensor(dec_out)\n",
    "\n",
    "def get_dataloader(dataset, batch_size, shuffle=True, drop_last=True, collate_fn=collate_fn):\n",
    "    '''\n",
    "    Returns a way to access and use the data\n",
    "    '''\n",
    "    dataloader = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            drop_last=drop_last,\n",
    "                            collate_fn=collate_fn)\n",
    "    return dataloader\n",
    "# Get PyTorch DataLoader\n",
    "dataloader = get_dataloader(dataset, batch_size)\n",
    "dataloader = get_dataloader(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "oVVbVP7l5AJg",
    "outputId": "e28da9fa-5fa2-4fbd-b4d3-49de9999475b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/0ddeade5-3577-4fe8-8cd6-8a0cb653428e/miniconda3/envs/nlp_env/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): GRU(64, 32, dropout=0.3)\n",
       "  (decoder): GRU(64, 32, dropout=0.3)\n",
       "  (embed_enc): Embedding(199, 64)\n",
       "  (embed_dec): Embedding(317, 64)\n",
       "  (fc): Linear(in_features=32, out_features=317, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2Seq(\n",
    "    in_maxlen = in_maxlen,\n",
    "    out_maxlen = out_maxlen,\n",
    "    n_hidden = n_hidden,\n",
    "    enc_n_class = len(input_tokenizer.dict),\n",
    "    dec_n_class = len(output_tokenizer.dict),\n",
    "    d_model = d_model,\n",
    "    num_layers = 1,\n",
    ")\n",
    "model.to(device)\n",
    "# # If you have saved a model before\n",
    "# model.load_state_dict(torch.load(\"seq2seq.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "id": "PtNvjmBo5A8W"
   },
   "outputs": [
   ],
   "source": [
    "# Define Loss and Optimizer -- these are ways we define performance for our model. If you're curious: https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "wVpmLnAtBLEV"
   },
   "source": [
    "<h1>Training our model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "PTSlF8fk5QpG",
    "outputId": "3eb0df28-80b9-452b-e9b5-5c7ffff27c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 576.2747802734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 280.32415771484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 238.6700897216797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 217.3397674560547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Loss: 193.51229858398438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Loss: 168.69577026367188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60, Loss: 144.92808532714844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70, Loss: 123.36004638671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80, Loss: 104.08132934570312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90, Loss: 87.08438873291016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 72.41958618164062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Loss: 59.867557525634766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120, Loss: 49.38654708862305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130, Loss: 40.73469161987305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140, Loss: 33.71730041503906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150, Loss: 28.130598068237305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 160, Loss: 23.55632781982422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170, Loss: 19.924890518188477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 180, Loss: 16.938188552856445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 190, Loss: 14.635987281799316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200, Loss: 12.67483139038086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 210, Loss: 11.050590515136719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220, Loss: 9.96059513092041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 230, Loss: 8.723247528076172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 240, Loss: 7.7913641929626465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250, Loss: 7.6860761642456055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 260, Loss: 6.983063220977783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270, Loss: 6.475579738616943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 280, Loss: 5.597828388214111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 290, Loss: 5.036618709564209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300, Loss: 4.595510482788086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 310, Loss: 4.232182502746582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320, Loss: 3.958742618560791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 330, Loss: 3.670031785964966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 340, Loss: 3.41642165184021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350, Loss: 3.19545316696167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360, Loss: 2.9968225955963135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 370, Loss: 2.8598716259002686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 380, Loss: 2.6651551723480225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 390, Loss: 2.5117602348327637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400, Loss: 2.38970947265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 410, Loss: 2.2810122966766357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 420, Loss: 2.163372039794922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 430, Loss: 2.044552803039551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 440, Loss: 1.9543917179107666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 450, Loss: 1.8725786209106445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 460, Loss: 1.7766356468200684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 470, Loss: 1.69122314453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 480, Loss: 1.9904934167861938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 490, Loss: 9.795100212097168\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: change the number of epochs to see how it effects training time and quality\n",
    "'''\n",
    "epochs = 500\n",
    "\n",
    "\n",
    "'''\n",
    "Training -- no need to touch the code below.\n",
    "'''\n",
    "torch.cuda.empty_cache()\n",
    "model.train()\n",
    "model.to(device)\n",
    "loss_records = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # runs the model and calculates loss\n",
    "    loss = 0\n",
    "    for _, (enc_in, dec_in, dec_out) in enumerate(dataloader):\n",
    "        # enc_h_0.shape: [1(num_layers), 1(batch_size), 32(hidden_size)]\n",
    "        enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n",
    "        # To Cuda Device if available\n",
    "        enc_in, dec_in = enc_in.to(device), dec_in.to(device)\n",
    "        \n",
    "        pred = model(enc_in, enc_h_0, dec_in)\n",
    "        \n",
    "        dec_out = dec_out.to(device)\n",
    "        for i in range(len(dec_out)): # dec_in.shape: [1(b), 40(out_maxlen)]\n",
    "            # pred[i].shape: [40(out_maxlen), 317(dec_n_class)]\n",
    "            # dec_out[i].shape: [40(out_maxlen)]\n",
    "            loss += criterion(pred[i], dec_out[i])\n",
    "\n",
    "    if (epoch) % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "\n",
    "    if (epoch) % 100 == 0:\n",
    "        loss_records.append(loss)\n",
    "    \n",
    "    # runs the actual back propacation\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    torch.save(model.state_dict(), \"seq2seq.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Let's check out our model's progress\n",
    "No need to change the code below, this will plot our loss over time. How do you think we can tweak our code to decrease loss even further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "id": "DCWlner5CkY-"
   },
   "outputs": [
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "%matplotlib inline\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points): # Helper function for showing our plots\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "collapsed": false,
    "id": "WGjbNIopCkzd",
    "outputId": "dc2375cb-efe2-4756-dd01-309e4f056e1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 13,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 3158 ticks ([-26.400000000000002, ..., 605.0000000000001]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showPlot([loss.cpu().item() for loss in loss_records])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Code for Translating with our Model</h1>\n",
    "This is where the Seq2Seq happens after the model is trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "id": "XHs9IRJK8usV"
   },
   "outputs": [
   ],
   "source": [
    "'''\n",
    "No need to touch this code: \n",
    "'''\n",
    "\n",
    "def translate(eng_sent, model, device):\n",
    "    # set up the inputs and variables\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    eng_sent = tk.tokenize(eng_sent.lower()) + [\"<EOS>\"]\n",
    "    eng_sent = input_tokenizer.transform(eng_sent, max_len=in_maxlen, pad_first=False)\n",
    "    dec_in = ([\"<SOS>\"] + [\"<PAD>\"]*out_maxlen)[:out_maxlen]\n",
    "    dec_in = output_tokenizer.transform(dec_in, max_len=out_maxlen, pad_first=False)\n",
    "    \n",
    "    enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n",
    "    eng_sent, dec_in = torch.LongTensor(eng_sent), torch.LongTensor(dec_in)\n",
    "\n",
    "    eng_sent = eng_sent.unsqueeze(0)\n",
    "    dec_in = dec_in.unsqueeze(0)\n",
    "    eng_sent, dec_in = eng_sent.to(device), dec_in.to(device)\n",
    "\n",
    "    # run the model\n",
    "    with torch.no_grad():\n",
    "        # eng_sent: [1(b), 26(in_maxlen)]\n",
    "        embedded_X = model.embed_enc(eng_sent)\n",
    "        # embedded_X: [26(in_maxlen), 1(b), 64(d_model)] <- [1(b), 26(in_maxlen), 64(d_model)]\n",
    "        embedded_X = embedded_X.permute(1, 0, 2)\n",
    "        _, memory = model.encoder(embedded_X, enc_h_0)\n",
    "        pred_loc = 0\n",
    "        for i in range(out_maxlen-1):\n",
    "            embedded_Y = model.embed_dec(dec_in)\n",
    "            embedded_Y = embedded_Y.permute(1, 0, 2)\n",
    "            outputs, _ = model.decoder(embedded_Y, memory)\n",
    "            outputs = outputs.permute(1, 0, 2)\n",
    "            pred = model.fc(outputs)\n",
    "            pred = pred[0][pred_loc].topk(1)[1].item()\n",
    "            pred_loc += 1\n",
    "            if pred == 2:\n",
    "                dec_in[0][pred_loc] = pred\n",
    "                break\n",
    "            else:\n",
    "                dec_in[0][pred_loc] = pred\n",
    "    return dec_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "kG_fTQzoBsMu"
   },
   "source": [
    "# Using our Model in Practice\n",
    "Check out these examples below. This is how you can translate sequences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "fh0-iZdvBUFF",
    "outputId": "f42cb9ed-a961-4d0f-c94c-6be4fb8d6656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The importation of rare wild animals to this country is strictly prohibited. -> \n",
      "该国<UNK><UNK><UNK>口<UNK>有野生<UNK>物。\n",
      "Charles Lindbergh made the first solo flight across the Atlantic Ocean in 1927. -> \n",
      "<UNK>har<UNK>e<UNK> <UNK><UNK><UNK><UNK><UNK>er<UNK>h於192<UNK>年成<UNK>完成了<UNK>一次<UNK>自飛<UNK>大西<UNK>。\n",
      "We were talking about something at that time, but I don't remember what. -> \n",
      "我们那时在<UNK>论事情，但我不记得是什么了。\n",
      "I'm a foreigner and I don't know Czech very well. Please, speak slowly. -> \n",
      "我是外国人，<UNK>的<UNK>语不好，<UNK>说<UNK>一点。\n",
      "If it's at all possible, I'd like you to take part in the next meeting. -> \n",
      "如果你想去，就去好了。如果你不想去，那也没什么大不了的。\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "eng_sents = random.sample(input_texts, 5)\n",
    "for sent in eng_sents:\n",
    "  translated = translate(sent, model, torch.device(\"cpu\"))\n",
    "  translated_sent = output_tokenizer.inverse_transform(translated[0], is_tensor=True)\n",
    "  translated_sent = \"\".join([word for word in translated_sent if word != \"<SOS>\" and word != \"<EOS>\"and word != \"<PAD>\"])\n",
    "  print(f\"{sent} -> \\n{translated_sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Your turn!\n",
    "\n",
    "Can you use the code in the cell above to translate custom sentences? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a student. -> \n",
      "我想知道这个城市，而且我一点都不懂那里的语言。\n",
      "What -> \n",
      "我想知道最<UNK>的美國<UNK>通<UNK>事<UNK>的電話<UNK><UNK>。\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: translate custom sentences using the code above. Hint: You won't need a for loop!\n",
    "'''\n",
    "eng_sents = ['I am a student.', 'What']\n",
    "for sent in eng_sents:\n",
    "  translated = translate(sent, model, torch.device(\"cpu\"))\n",
    "  translated_sent = output_tokenizer.inverse_transform(translated[0], is_tensor=True)\n",
    "  translated_sent = \"\".join([word for word in translated_sent if word != \"<SOS>\" and word != \"<EOS>\"and word != \"<PAD>\"])\n",
    "  print(f\"{sent} -> \\n{translated_sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
   ],
   "name": "Seq2Seq en-cn.ipynb",
   "provenance": [
   ]
  },
  "interpreter": {
   "hash": "335ee12212264728feb72f243af72c5a8ea26c832f07e1f651ce9e17c7ceae23"
  },
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "nlp_env",
   "resource_dir": "/projects/0ddeade5-3577-4fe8-8cd6-8a0cb653428e/.local/share/jupyter/kernels/nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}